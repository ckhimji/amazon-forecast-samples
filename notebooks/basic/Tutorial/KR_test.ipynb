{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Amazon Forecast to predict P&G future sales in Oman\n",
    "Chirayu Khimji\n",
    "\n",
    "MSc Applied Computational Science and Engineering\n",
    "\n",
    "Imperial College London\n",
    "\n",
    "\n",
    "Note: This notebook will not run on other machines due to privacy aspect of uploading P&G data (data is stored locally on my machine), its purpose is just to showcase the power of data science for KR CPG group.\n",
    "\n",
    "The overall process for using Amazon Forecast is the following:\n",
    "\n",
    "1. Create a Dataset Group, this is the large box that isolates models and the data they are trained on from each other.\n",
    "2. Create a Dataset, in Forecast there are 3 types of dataset, Target Time Series, Related Time Series, and Item Metadata. The Target Time Series is required, the others provide additional context with certain algorithms. \n",
    "3. Import data, this moves the information from S3 into a storage volume where the data can be used for training and validation.\n",
    "4. Train a model, Forecast automates this process for you but you can also select particular algorithms, and you can provide your own hyper parameters or use Hyper Parameter Optimization(HPO) to determine the most performant values for you.\n",
    "5. Deploy a Predictor, here you are deploying your model so you can use it to generate a forecast.\n",
    "6. Query the Forecast, given a request bounded by time for an item, return the forecast for it. Once you have this you can evaluate its performance or use it to guide your decisions about the future.\n",
    "\n",
    "In this notebook we walk through the steps outlined above. One additional task that will be done here is to trim part of our training and validation data so that we can measure the accuracy of a forecast against our predictions. \n",
    "\n",
    "\n",
    "## Table Of Contents\n",
    "* Setup\n",
    "* Data Preparation\n",
    "* Creating the Dataset Group and Dataset\n",
    "* Next Steps\n",
    "\n",
    "\n",
    "**Read Every Cell FULLY before executing it**\n",
    "\n",
    "For more informations about APIs, please check the [documentation](https://docs.aws.amazon.com/forecast/latest/dg/what-is-forecast.html)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the standard Python libraries that are used in this lesson.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import boto3\n",
    "\n",
    "# importing forecast notebook utility from notebooks/common directory\n",
    "sys.path.insert( 0, os.path.abspath(\"../../common\") )\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the S3 bucket name and region name for this lesson.\n",
    "\n",
    "- If you don't have an S3 bucket, create it first on S3. If you used CloudFormation Wizard to set up the environment, use same bucket name as you specified in the setup process.\n",
    "- Although we have set the region to us-west-2 as a default value below, you can choose any of the regions that the service is available in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Text(value='', description='bucket_name', placeholder='input your S3 bucket name')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9635565f10f4bab9336e5a3a9e9c7c8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Text(value='us-west-2', description='region', placeholder='input region name.')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d44e2fc9e19d436ea2091c77c70a7096"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "##Code needs to be fixed\n",
    "text_widget_bucket = util.create_text_widget( \"bucket_name\", \"input your S3 bucket name\" )\n",
    "text_widget_region = util.create_text_widget( \"region\", \"input region name.\", default_value=\"us-west-2\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code needs to be fixed\n",
    "bucket_name = text_widget_bucket.value\n",
    "#assert bucket_name, \"bucket_name not set.\"\n",
    "\n",
    "region = text_widget_region.value\n",
    "#assert region, \"region not set.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part of the setup process is to validate that your account can communicate with Amazon Forecast, the cell below does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code needs to be fixed\n",
    "session = boto3.Session(region_name=region) \n",
    "forecast = session.client(service_name='forecast') \n",
    "forecastquery = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "First we combine all the p&gsales_*.csv files using Pandas. This is done inorder to get one data frame which is chronologically sorted as a time series from 2016 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel(\"./p&gsales_1.xlsx\", index_col = \"Customer\")\n",
    "df1 = pd.read_csv(\"./p&gsales_1.csv\", index_col=\"Date\")\n",
    "df2 = pd.read_csv(\"./p&gsales_2.csv\", index_col=\"Date\")\n",
    "df3 = pd.read_csv(\"./p&gsales_3.csv\", index_col=\"Date\")\n",
    "df4 = pd.read_csv(\"./p&gsales_4.csv\", index_col=\"Date\")\n",
    "\n",
    "frames = [df1, df2, df3, df4]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first 5 entries i.e. make sure they start as p&gsales_1.csv starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Customer                    Name Material                 Article  \\\nDate                                                                            \n03/01/2016  60000707  LULU HYPERMARKET-SOHAR   179045      TIDE NS  FLA 1.5KG   \n03/01/2016  60000707  LULU HYPERMARKET-SOHAR   179047     TIDE NS FLA WED 3KG   \n03/01/2016  60000707  LULU HYPERMARKET-SOHAR   179051       TIDE NS  MB 260GM   \n03/01/2016  60000707  LULU HYPERMARKET-SOHAR   179053         TIDE NS  MB 3KG   \n03/01/2016  60000707  LULU HYPERMARKET-SOHAR   179058  TIDE NS  JASMINE 1.5KG   \n\n            Billed Value  Billed Qty  \nDate                                  \n03/01/2016        40.752        24.0  \n03/01/2016        13.296         4.0  \n03/01/2016        18.176        64.0  \n03/01/2016        13.296         4.0  \n03/01/2016        40.752        24.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer</th>\n      <th>Name</th>\n      <th>Material</th>\n      <th>Article</th>\n      <th>Billed Value</th>\n      <th>Billed Qty</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>03/01/2016</th>\n      <td>60000707</td>\n      <td>LULU HYPERMARKET-SOHAR</td>\n      <td>179045</td>\n      <td>TIDE NS  FLA 1.5KG</td>\n      <td>40.752</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>03/01/2016</th>\n      <td>60000707</td>\n      <td>LULU HYPERMARKET-SOHAR</td>\n      <td>179047</td>\n      <td>TIDE NS FLA WED 3KG</td>\n      <td>13.296</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>03/01/2016</th>\n      <td>60000707</td>\n      <td>LULU HYPERMARKET-SOHAR</td>\n      <td>179051</td>\n      <td>TIDE NS  MB 260GM</td>\n      <td>18.176</td>\n      <td>64.0</td>\n    </tr>\n    <tr>\n      <th>03/01/2016</th>\n      <td>60000707</td>\n      <td>LULU HYPERMARKET-SOHAR</td>\n      <td>179053</td>\n      <td>TIDE NS  MB 3KG</td>\n      <td>13.296</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>03/01/2016</th>\n      <td>60000707</td>\n      <td>LULU HYPERMARKET-SOHAR</td>\n      <td>179058</td>\n      <td>TIDE NS  JASMINE 1.5KG</td>\n      <td>40.752</td>\n      <td>24.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the last 5 entries i.e. make sure they end as p&gsales_4.csv ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Customer                                 Name Material  \\\nDate                                                                 \n30/04/2020  60097965  ROYAL STAR INT'L LLC - NESTO - SAAD   212450   \n30/04/2020  60097965  ROYAL STAR INT'L LLC - NESTO - SAAD   248420   \n30/04/2020  60097965  ROYAL STAR INT'L LLC - NESTO - SAAD   266730   \n30/04/2020  60097965  ROYAL STAR INT'L LLC - NESTO - SAAD   267363   \n30/04/2020  60097965  ROYAL STAR INT'L LLC - NESTO - SAAD   283299   \n\n                                            Article  Billed Value  Billed Qty  \nDate                                                                           \n30/04/2020   PANTENE ATLAS ANTI DANDRUFF SHMP 400ML        -8.556        -6.0  \n30/04/2020       HE SHMP ARABICA COFFEE FRUIT 400ML       -22.128       -12.0  \n30/04/2020  ADIDAS AP ROLL-ON FEMALE CLIMACOOL 50ML        -6.240        -6.0  \n30/04/2020               OB KIDS FROZEN & CARS 75ML       -15.096       -12.0  \n30/04/2020         GILL BLUE3 COMFORT DISPOSABLE 6S       -27.360       -12.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer</th>\n      <th>Name</th>\n      <th>Material</th>\n      <th>Article</th>\n      <th>Billed Value</th>\n      <th>Billed Qty</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30/04/2020</th>\n      <td>60097965</td>\n      <td>ROYAL STAR INT'L LLC - NESTO - SAAD</td>\n      <td>212450</td>\n      <td>PANTENE ATLAS ANTI DANDRUFF SHMP 400ML</td>\n      <td>-8.556</td>\n      <td>-6.0</td>\n    </tr>\n    <tr>\n      <th>30/04/2020</th>\n      <td>60097965</td>\n      <td>ROYAL STAR INT'L LLC - NESTO - SAAD</td>\n      <td>248420</td>\n      <td>HE SHMP ARABICA COFFEE FRUIT 400ML</td>\n      <td>-22.128</td>\n      <td>-12.0</td>\n    </tr>\n    <tr>\n      <th>30/04/2020</th>\n      <td>60097965</td>\n      <td>ROYAL STAR INT'L LLC - NESTO - SAAD</td>\n      <td>266730</td>\n      <td>ADIDAS AP ROLL-ON FEMALE CLIMACOOL 50ML</td>\n      <td>-6.240</td>\n      <td>-6.0</td>\n    </tr>\n    <tr>\n      <th>30/04/2020</th>\n      <td>60097965</td>\n      <td>ROYAL STAR INT'L LLC - NESTO - SAAD</td>\n      <td>267363</td>\n      <td>OB KIDS FROZEN &amp; CARS 75ML</td>\n      <td>-15.096</td>\n      <td>-12.0</td>\n    </tr>\n    <tr>\n      <th>30/04/2020</th>\n      <td>60097965</td>\n      <td>ROYAL STAR INT'L LLC - NESTO - SAAD</td>\n      <td>283299</td>\n      <td>GILL BLUE3 COMFORT DISPOSABLE 6S</td>\n      <td>-27.360</td>\n      <td>-12.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the dimensions of this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3056772, 6)\n"
    }
   ],
   "source": [
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Cleaning the data and formatting columns to correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbaseconda55a49d4626844cf39c6eb629cecf414d",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}